name: ğŸš€ Scrape News & Deploy to Netlify

on:
  # Tourne toutes les 6 heures (0h, 6h, 12h, 18h UTC)
  schedule:
    - cron: '0 */6 * * *'

  # Aussi quand tu push sur master
  push:
    branches:
      - master

  # Et permet de lancer manuellement
  workflow_dispatch:

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸ”„ Run scraper
        run: |
          python3 -m scraper.scraper
        env:
          PYTHONUNBUFFERED: 1

      - name: ğŸ—ï¸ Build static site
        run: |
          python3 build_static.py

      - name: ğŸ”„ Move build output to docs/
        run: |
          mv public docs

      - name: ï¿½ Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          if [[ -n $(git status -s) ]]; then
            git add data/ia_news.json docs/
            git commit -m "ğŸ¤– Auto-update: Scrape news articles"
            git push
          else
            echo "âœ… No changes to commit"
          fi

      - name: ğŸš€ Deploy to Netlify
        uses: nwtgck/actions-netlify@v2.0
        with:
          publish-dir: './docs'
          production-deploy: true
          netlify-config-path: ./netlify.toml
        env:
          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}
          NETLIFY_SITE_ID: ${{ secrets.NETLIFY_SITE_ID }}
        timeout-minutes: 1
